{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Cloud Resumé Challenge: Part 3\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is part three of the AWS Cloud Resumé Challenge, in which I productize the creation of the AWS Cloud configuration that I previously created by clicking around in the AWS Console, like a demented Click Monkey.\n",
    "\n",
    "Having the AWS setup as a code file, then allows it to be placed under configuration control: Configuration as Code.\n",
    "\n",
    "I found a few wrinkles and gotchas that I will go through below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Recap\n",
    "\n",
    "The design that I will be creating by configuration code is that below (figure from a previous post)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/arch-02.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Browser client has embedded Javascript code that calls the endpoint of an API Gateway instance.  The API Gateway instance calls a AWS Lambda function, that reads, increments, and writes back a counter held in a DynamoDB datatable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "## Design Choices\n",
    "\n",
    "### Play it again, Sam\n",
    "\n",
    "The configuration language I could have used is called AWS CloudFormation, which is the more general purpose configuration language.  However, Amazon (and the general AWS Cloud community) heavily push the AWS Serverless Application Model (SAM) option. Configurations in SAM are build into CloudFormation specifications, but are much more concise, and a lot of the \"best-practice\" work is done for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsides\n",
    "\n",
    "One gotcha I encountered in dealing with AWS SAM is that it is much better to do everything through SAM.  Performing AWS Cloud operations (like deleting a DynamoDB datatable) in the AWS Console can confuse SAM when it comes time to build the configuration again.  The official AWS advice for this case is \"re-create every thing you deleted, and try again!\". \n",
    "\n",
    "You do have to become familiar with CloudFormation terminology (as it is SAM terminolgy too).  The key concept is a __Stack__; a set of AWS capabilities that operate, and are linked, to achieve some task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## SAM Configuration Walkthrough\n",
    "\n",
    "I found that it was best to incrementally learn SAM by creating parts of the processing chain in isolation.  First the DynamoDB database table, then the Lambda Function.  I won't go through all my interim steps, but just walk through my final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I am a Windows user, I went very old-school, and have a ```.bat``` file to run my builds.\n",
    "\n",
    "Excluding the header comments, it looks like:\n",
    "\n",
    "```\n",
    "ECHO ON\n",
    "ECHO Deleting previous stack\n",
    "call aws cloudformation delete-stack --stack-name loadcounter01\n",
    "call aws cloudformation wait stack-delete-complete --stack-name loadcounter01\n",
    "REM -----------------------------\n",
    "ECHO ON\n",
    "ECHO Starting SAM Build\n",
    "call sam build \n",
    "ECHO Starting SAM Deploy\n",
    "call sam deploy --guided \n",
    "ECHO Loading initial data\n",
    "call aws dynamodb batch-write-item --request-items file://initialloaddata.json\n",
    "```\n",
    "\n",
    "Note that I am hard-coding the name of my stack in this script (```loadcounter01```).\n",
    "\n",
    "To walk through each command:\n",
    "\n",
    "```\n",
    "aws cloudformation delete-stack --stack-name loadcounter01\n",
    "```\n",
    "I expect to be running this script repeatably.  For this application I am happy to trash whatever state is stored in the database (the API Gateway instance, and the Lambda Function, have no state, by definition).  If I was concerned with maintaining my load-count across build, I would have to read the DynamoDB database, store the data, and reload it into the newly re-created database at the end of the script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the ```delete-stack``` command doesn't actually delete the CloudFormation stack, it only initiates the delete operation.  You have to wait to is is complete, via:\n",
    "\n",
    "```\n",
    "aws cloudformation wait stack-delete-complete --stack-name loadcounter01 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a clean slate.  We build the CloudFormation configuration via the \n",
    "```\n",
    "sam build\n",
    "```\n",
    "\n",
    "Then we deploy it.  I have chosen to use the ```--guided``` option so I could see what was happening, but if you added the appropriate command line options, this could be completely automated.\n",
    "\n",
    "```\n",
    "sam deploy --guided \n",
    "```\n",
    "\n",
    "Finally, I load an initial dataset into the DynamoDB datatable\n",
    "```\n",
    "aws dynamodb batch-write-item --request-items file://initialloaddata.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Script Outputs\n",
    "\n",
    "### SAM Build\n",
    "\n",
    "The results (in part) of running the script above are:\n",
    "\n",
    "```\n",
    "(ac5-py37) D:\\AWS-SAM-Working\\loadcounter01>call sam build\n",
    "Building function 'ManageCounterFunction'\n",
    "Running PythonPipBuilder:ResolveDependencies\n",
    "Running PythonPipBuilder:CopySource\n",
    "\n",
    "Build Succeeded\n",
    "\n",
    "Built Artifacts  : .aws-sam\\build\n",
    "Built Template   : .aws-sam\\build\\template.yaml\n",
    "\n",
    "Commands you can use next\n",
    "=========================\n",
    "[*] Invoke Function: sam local invoke\n",
    "[*] Deploy: sam deploy --guided\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the SAM deployment looks in part like:\n",
    "\n",
    "```\n",
    "Configuring SAM deploy\n",
    "======================\n",
    "\n",
    "        Looking for samconfig.toml :  Found\n",
    "        Reading default arguments  :  Success\n",
    "\n",
    "        Setting default arguments for 'sam deploy'\n",
    "        =========================================\n",
    "        Stack Name [loadcounter01]:\n",
    "        AWS Region [ap-southeast-2]:\n",
    "        #Shows you resources changes to be deployed and require a 'Y' to initiate deploy\n",
    "        Confirm changes before deploy [Y/n]: y\n",
    "        #SAM needs permission to be able to create roles to connect to the resources in your template\n",
    "        Allow SAM CLI IAM role creation [Y/n]: y\n",
    "        ManageCounterFunction may not have authorization defined, Is this okay? [y/N]: y\n",
    "        Save arguments to samconfig.toml [Y/n]: y\n",
    "\n",
    "        Looking for resources needed for deployment: Found!\n",
    "\n",
    "                Managed S3 bucket: aws-sam-cli-managed-default-samclisourcebucket-1dgbnny6g7a0\n",
    "                A different default S3 bucket can be set in samconfig.toml\n",
    "\n",
    "        Saved arguments to config file\n",
    "        Running 'sam deploy' for future deployments will use the parameters saved above.\n",
    "\n",
    "```\n",
    "\n",
    "Note that I had run this SAM configuration file many time in my debugging / development effort, and the deployment process had remembered some state.  First, the ```.toml``` file that remembered my previous choices for the ```guided``` deployment.  Second, the S3 Bucket used for deployment already existed, and so didn't need to be rebuilt.  Now I think about it, I wonder why it didn't get deleted in the ```delete-stack``` operation?  One thing to consider in the cleanup process if you decide to not use a CloudFormation Stack ever again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the desired configuration is known, SAM works out what needs changing (in my case, everything)\n",
    "\n",
    "\n",
    "|Operation     |LogicalResourceId                                      |ResourceType|\n",
    "|--------|--|--|\n",
    "|+ Add                                                 |LoadCounterTable                                      |AWS::DynamoDB::Table|\n",
    "|+ Add                                                  |ManageCounterFunctionCounterAccessApiPermissionProd   | AWS::Lambda::Permission|\n",
    "|+ Add                                                  |ManageCounterFunctionRole                             | AWS::IAM::Role|\n",
    "|+ Add                                                  |ManageCounterFunction                                 | AWS::Lambda::Function|\n",
    "|+ Add                                                  |ServerlessRestApiDeployment4b9917be34                 | AWS::ApiGateway::Deployment|\n",
    "|+ Add                                                  |ServerlessRestApiProdStage                            | AWS::ApiGateway::Stage|\n",
    "|+ Add                                                  |ServerlessRestApi                                     | AWS::ApiGateway::RestApi|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You then get (because of ```--guided```) to decide whether to proceed\n",
    "\n",
    "```\n",
    "Changeset created successfully. arn:aws:cloudformation:ap-southeast-2:261204630592:changeSet/samcli-deploy1598338401/94778c3f-f4cd-45c4-993a-21e4cd31b500\n",
    "\n",
    "\n",
    "Previewing CloudFormation changeset before deployment\n",
    "======================================================\n",
    "Deploy this changeset? [y/N]: y\n",
    "\n",
    "2020-08-25 16:53:39 - Waiting for stack create/update to complete\n",
    "```\n",
    "\n",
    "You then get a  number of CREATE_IN_PROGRESS and CREATE_COMPLETE messages, and finally:\n",
    "\n",
    "```\n",
    "Successfully created/updated stack - loadcounter01 in ap-southeast-2\n",
    "```\n",
    "\n",
    "\n",
    "The final DynamoDB ```batch-write``` is silent, but I guess would complain if the expected data table was not present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order for our soon-to-be-constructed webpage to be able to use this Stack, we have to know the \n",
    "endpoint by which we can access the API Gateway instance.  In my SAM configuration (described below), I create a ```Stack Output```, that gives this endpoint.\n",
    "\n",
    "So by running a command as below, we can get this endpoint.\n",
    "```\n",
    "(ac5-py37) D:\\AWS-SAM-Working\\loadcounter01>aws cloudformation describe-stacks --stack-name loadcounter01 --query Stacks[0].Outputs[?OutputKey==`CounterAccessApi`].OutputValue  --output text\n",
    "https://byhpjqrzn9.execute-api.ap-southeast-2.amazonaws.com/Prod/counter/\n",
    "```\n",
    "\n",
    "This says: \n",
    "\n",
    "- get the first Stack in the list I am processing (and because I specified the stackname explicitly, there is only one Stack)\n",
    "\n",
    "- get the Output with the OutputKey equal to a key we have defined in the configuration file\n",
    "\n",
    "- get the OutputValue\n",
    "\n",
    "- show it as text (could be JSON, etc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have an endpoint (```https://byhpjqrzn9.execute-api.ap-southeast-2.amazonaws.com/Prod/counter/```) that I can use in my Javascript in my webpage.\n",
    "\n",
    "I cheated:  I manually edited the webpage Javascript in ```resume.html```, and reloaded it into the S3 Bucket that AWS CloudFront is using as the source of my webpage.  But I could have automated this process, honest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us:\n",
    "\n",
    "![](images/loadcounter01-01.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note again the warning about my (mis)use of the Synchronous XMLHttpRequest.  I have decided that it is acceptable in my circumstances, where back-end processing is minimal, and minimising page-load times are not a significant design issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## SAM Configuration Walkthrough\n",
    "\n",
    "What follows is a walkthrough of my SAM configuration YAML file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header comments\n",
    "\n",
    "```\n",
    "# ----------------------------------------\n",
    "# ASW SAM YAML Template\n",
    "#\n",
    "# Purpose:\n",
    "# To create:\n",
    "#     a DynamoDB database, for page load count statistics\n",
    "#     a AWS Lambda function with HTTP endpoint\n",
    "#\n",
    "#     Lambda function will read and increment a counter, and update\n",
    "#     counter in database\n",
    "#\n",
    "# The API endpoint will be called via Javascript from a HTML page\n",
    "#\n",
    "# Notes:\n",
    "# - DynamoDB table name must match that used in the Lambda Function Python\n",
    "# - DynamoDB table primary key must match that used in Lambda Function Python\n",
    "# - The Lambda API endpoint must match that used in the Javascript of the Resume Web Page\n",
    "# - Initial data load script must define a secondary attribute 'loadcount'\n",
    "#    initialized to an integer value\n",
    "# - Initial data load must create row with 'appname'== 'ResumeApp'\n",
    "#\n",
    "#  - The Lambda function is granted full access to DynamoDB - may be excessive?\n",
    "#\n",
    "# Author - D Cameron  donrcameron@gmail.com\n",
    "# Date - 2020-08-24\n",
    "#\n",
    "```\n",
    "\n",
    "I was not able to find any SAM header comment standards or guidelines, so I invented my own.  In this header,\n",
    "I tried to define all the moving parts that had to mesh (and, of course, should be automated).\n",
    "\n",
    "For example, I could have defined the DynamoDB table name externally, and automatically ensured that\n",
    "it was the same the in the Lambda Python and in this configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two lines are mandatory  (I don't know if there are any other Transforms defined by Amazon or third parties)\n",
    "\n",
    "```\n",
    "AWSTemplateFormatVersion: \"2010-09-09\"\n",
    "Transform: AWS::Serverless-2016-10-31\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I elected to have place-holders for all the SAM top-level sections I don't use.  The ```Description``` section briefly states the purpose of the SAM for display in the AWS Console\n",
    "\n",
    "```\n",
    "Description: Creates a HTTP API Function and DynamoDB datatable\n",
    "# end Description\n",
    "\n",
    "# Globals:\n",
    "#   No Globals defined\n",
    "\n",
    "# Metadata:\n",
    "#   No Metadata defined\n",
    "\n",
    "# Parameters:\n",
    "#   No Parameters defined\n",
    "\n",
    "# Mappings:\n",
    "#   No mappings defined\n",
    "\n",
    "# Conditions:\n",
    "#   No Conditions defined\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main meat of the SAM is in the Resources section\n",
    "\n",
    "```\n",
    "Resources:\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database Specification\n",
    "The first resource we define is the DynamoDB table.  As an aside, I find it hard to track levels of indentation, so I like to show explicitly where sub-sections begin and end.  I usually choose to have all name and identifiers used across boundaries to be all lowercase, to reduce possible sources of error.\n",
    "\n",
    "```\n",
    "  # --------------------------------------\n",
    "  # define a DynamoDB table resource\n",
    "  LoadCounterTable:\n",
    "    Type: AWS::Serverless::SimpleTable\n",
    "    Properties:\n",
    "      # Creates a DynamoDB table with a single attribute\n",
    "      # primary key. It is useful when data only needs to be\n",
    "      # accessed via a primary key.\n",
    "      TableName: loadcounter2\n",
    "      PrimaryKey:\n",
    "        Name: appname\n",
    "        Type: String\n",
    "      ProvisionedThroughput:\n",
    "        # 5 reads/writes per second before throttling should be ample\n",
    "        # expect access to be in 5 reads/writes a day\n",
    "        ReadCapacityUnits: 5\n",
    "        WriteCapacityUnits: 5\n",
    "      # Tags:\n",
    "      #   No Tags defined\n",
    "      # SSESpecification\n",
    "      #   No Server Side Encryption defined\n",
    "  #end LoadCounterTable:\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda Function\n",
    "The second resource is our Lambda Function.  We specify that our Lambda code is in Python 3.7, and is held in a file app.py held in the directory Lambda, and the function to be called to handle events is ```lambda_handler```.  We know our Lambda function needs access to DynamoDB, so we define a policy (predefined by AWS) that allows this.\n",
    "\n",
    "About the only wrinkle here (and the main difference between this solution, and the previous AWS Console solutions), is that the API Gateway instance we create is implicit in the definition of the Events that will trigger this Lambda.\n",
    "\n",
    "This means that the Cross-Origin Resource Sharing (CORS) configuration to allow general browser access has to be done at run-time, in our Python Lamda code. This will be shown below.  \n",
    "\n",
    "```\n",
    "  # --------------------------------------\n",
    "  # Define an HTTP API Lambda Function\n",
    "  ManageCounterFunction:\n",
    "    Type: AWS::Serverless::Function\n",
    "    Properties:\n",
    "      CodeUri: Lambda/\n",
    "      Handler: app.lambda_handler\n",
    "      Runtime: python3.7\n",
    "      Policies:\n",
    "        # Give DynamoDB Full Access to the Lambda Function\n",
    "        AmazonDynamoDBFullAccess\n",
    "      Events:\n",
    "        CounterAccessApi:\n",
    "          Type: Api\n",
    "          Properties:\n",
    "            Path: /counter\n",
    "            Method: get\n",
    "  # end ManageCounterFunction\n",
    "  # --------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define an output for our Stack, that actually exposes the endpoint for the API Gateway instance.  In AWS SAM, the Stage used seems to be hardcoded to ```Prod```, and the internal AWS documentation says _\"This API defaults to a StageName called \"Prod\" that cannot be configured\"_\n",
    "\n",
    "The two expressions enclosed in ```{``` and ```}``` are either:\n",
    "\n",
    "- CloudFormation resources generated By SAM (AWS::ApiGateway::RestApi -> ServerlessRestApi), or\n",
    "- Pseudo parameters, that are parameters  predefined by AWS CloudFormation (AWS::Region returns a string representing the AWS Region)\n",
    "\n",
    "\n",
    "```\n",
    "Outputs:\n",
    "  # --------------------------------------\n",
    "  # Define a AWS CloudFormation Stack Output,\n",
    "  # that will show the HTTP URL to access function\n",
    "  #\n",
    "  # This can be accessed by\n",
    "  # aws cloudformation describe-stacks \\\n",
    "  # --stack-name loadcounter01 \\\n",
    "  # --query Stacks[0].Outputs[?OutputKey==`CounterAccessApi`].OutputValue  \\\n",
    "  # --output text\n",
    "  CounterAccessApi:\n",
    "    Description: \"endpoint for api to python \"\n",
    "    Value: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/counter/\"\n",
    "  # end CounterAccessApi\n",
    "# end Outputs -----------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Python Business Logic\n",
    "\n",
    "The Python code is fairly simple:\n",
    "\n",
    "- get current load count, held as string in DynamoDB \n",
    "- increment value\n",
    "- store updated counter back into DynamoDB\n",
    "- return value to caller\n",
    "\n",
    "Note:\n",
    "\n",
    "- there are two API's to write to the DynamoDB; I used the newer, preferred call (but it is slightly more complicated)\n",
    "- in order for browser access to this function, I need CORS enabled.  This is done by explicitly writing back the HTTP\n",
    "headers that says we are prepared to accepts requests from any DNS domain.\n",
    "\n",
    "```\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "table = dynamodb.Table('loadcounter2')\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    response = table.get_item(Key={'appname': 'ResumeApp'})\n",
    "    count = response[\"Item\"][\"loadcount\"]\n",
    "\n",
    "    # increment string version of visit count\n",
    "    new_count = str(int(count) + 1)\n",
    "    response = table.update_item(\n",
    "        Key={'appname': 'ResumeApp'},\n",
    "        UpdateExpression='set loadcount = :c',\n",
    "        ExpressionAttributeValues={':c': new_count},\n",
    "        ReturnValues='UPDATED_NEW',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"headers\": {\n",
    "            \"Access-Control-Allow-Headers\": \"Content-Type\",\n",
    "            \"Access-Control-Allow-Origin\": \"*\",\n",
    "            \"Access-Control-Allow-Methods\": \"OPTIONS,POST,GET\",\n",
    "        },\n",
    "        \"body\": json.dumps(new_count),\n",
    "    }\n",
    "\n",
    "# end lambda_handler\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Javascript Presentation Logic\n",
    "\n",
    "The presentation logic is straightforward.  When the resume page has loaded, make a XMLHttpRequest, extract the current counter, and store in a predefined field in the page.\n",
    "\n",
    "```\n",
    "    function getLoadCount(){\n",
    "\n",
    "        // call an AWS gateway API, that then calls an AWS Lambda\n",
    "        // to read and then update AWS DynamoDB item showing load count\n",
    "\n",
    "        // Note call is synchronous, delays should be minimal\n",
    "        var req = new XMLHttpRequest();  \n",
    "        req.open('GET', \n",
    "        \"https://byhpjqrzn9.execute-api.ap-southeast-2.amazonaws.com/Prod/counter/\", \n",
    "        false);   \n",
    "        req.send();  \n",
    "        if(req.status == 200)\n",
    "            {  \n",
    "                len = req.responseText.length;\n",
    "                // response text has opening and closing double quotes\n",
    "                console.log(req.responseText.substring(1, len-1));\n",
    "                // set field in footer\n",
    "                document.getElementById(\"loadcount\").textContent = \n",
    "                    req.responseText.substring(1, len-1);\n",
    "            }\n",
    "        else {\n",
    "            // NOT OK response, so log in console\n",
    "            console.log(req.status)\n",
    "        }//end if\n",
    "    }// end getLoadCount\n",
    "\n",
    "    // read and write visit count into footer, then increment count in DB\n",
    "    window.onload = function(){\n",
    "\n",
    "            // side effects\n",
    "            // getLoadCount() updates field in footer, increments count in DB\n",
    "            getLoadCount();\n",
    "        }; //end window.onload\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## AWS Console View\n",
    "\n",
    "We can view the results of the Stack deployment in the AWS Console.\n",
    "\n",
    "First the Stack we have created and deployed.\n",
    "\n",
    "\n",
    "![](images/loadcounter01-02.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the Resources created by  deploying this Stack.\n",
    "\n",
    "![](images/loadcounter01-03.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datatable in DynamoDB.\n",
    "\n",
    "![](images/loadcounter01-04.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API Gateway instance.\n",
    "\n",
    "![](images/loadcounter01-05.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-05.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lambda Function.\n",
    "\n",
    "![](images/loadcounter01-06.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Application view\n",
    "\n",
    "When you view the Lambda Functuion via the AWS Console, the Console knows the Lambda Function is part of an application, and it offers a view of it.\n",
    "\n",
    "\n",
    "![](images/loadcounter01-07.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-07.png)\n",
    "\n",
    "\n",
    "The view looks like:\n",
    "\n",
    "![](images/loadcounter01-08.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-08.png)\n",
    "\n",
    "with deployment and monitoring views:\n",
    "\n",
    "### Deployment view\n",
    "\n",
    "![](images/loadcounter01-09.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-09.png)\n",
    "\n",
    "\n",
    "### Monitoring view\n",
    "\n",
    "\n",
    "![](images/loadcounter01-10.png)\n",
    "\n",
    "[Larger image of above](images/loadcounter01-10.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Conclusions\n",
    "\n",
    "I must say that I feel very unsatisfied with my solution, for a number of reasons.  I feel like someone who has scratched out a \"Hello World\" app, but who knows there is much more to software engineering that that.\n",
    "\n",
    "First, I didn't explore any other approaches.  For example, I might have defined a Lambda Function that was triggered by down-loads from my S3 Bucket holding my HTML, to update the database, and another Function for the browser to call to read from the database.  As I said initially, I just wanted to automatically re-create a manually crafted solution.\n",
    "\n",
    "More importantly, I feel there are significant design questions that this toy example ignores.  For example:\n",
    "\n",
    "- If I want to avoid Denial-of-Wallet attacks, how to I stop a malicious agent from running up huge bills for me?  I have attempted to control this by limiting database access, but I don't know if this works, or is best practice.  There is a \"Throttle\" button in the Lambda Console UI, but it seems to be a last-resort kill-switch.\n",
    "\n",
    "- What am I supposed to do with the Roles that have automatically been created?  I dimly suspect that I am supposed to use these to define Privilege Boundaries, and apply them to the Roles.  For example, the Lambda Function has access to all the database; I would like to limit it to one table, in case of code-injecting into my Lambda Function.\n",
    "\n",
    "- What security issues have I ignored?  For example, if a end-user disables Javascript, their download will not increment the download counter - in this case I don't care.  I suspect that I should have payed a lot more care in defining AWS Roles, and profiles to use in running SAM commands.\n",
    "\n",
    "- The full support for Staging (Development -> Test -> Production Beta -> Full Production) doesn't seem to be supported by SAM.  I don't know how to achieve this.\n",
    "\n",
    "Now clearly the questions (and many more) might be answered by a (years long)  structured study of AWS (rather than by my hobbyist Google / StackOverflow antics).\n",
    "\n",
    "Overall, I learned a lot about how AWS thinks you should compose applications, but I have a lot more to learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
